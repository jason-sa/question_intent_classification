{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Lemma + MVP\n",
    "\n",
    "This model will incorporate a lemmatization of the questions, by spaCy, to see if this improves upon on the MVP model. Regardless, the results will be scrutinized to determine if any patterns can be established of the pairs which are signficantly mis-classified.\n",
    "\n",
    "**Pipeline**:\n",
    "1. Stack questions\n",
    "2. Lemmatize questions\n",
    "3. TF-IDF\n",
    "4. NMF (5 topics)\n",
    "5. Unstack questions\n",
    "6. XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:13:46.839767Z",
     "start_time": "2018-11-26T15:13:32.811218Z"
    }
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:13:47.346738Z",
     "start_time": "2018-11-26T15:13:46.843181Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = utils.load('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:13:47.902341Z",
     "start_time": "2018-11-26T15:13:47.349045Z"
    }
   },
   "outputs": [],
   "source": [
    "X = utils.stack_questions(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:26:31.826693Z",
     "start_time": "2018-11-26T15:13:47.906016Z"
    }
   },
   "outputs": [],
   "source": [
    "#docs = utils.cleanup_text(X) # 42 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:26:31.841595Z",
     "start_time": "2018-11-26T15:26:31.829671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:26:31.852708Z",
     "start_time": "2018-11-26T15:26:31.845703Z"
    }
   },
   "outputs": [],
   "source": [
    "#vecs = utils.create_vectors(docs)## need to fix the error, but not needed for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:41:42.387865Z",
     "start_time": "2018-11-26T15:26:31.855006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('stack', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function stack_questions at 0x1a25aa5158>,\n",
       "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "          pass_y='deprecated', validate=False)), ('lemma', FunctionTransformer(accept_sparse=False, ch...ate=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.cleanup_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('nmf', NMF(n_components = 5)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False)),\n",
    "        ('xgb', XGBClassifier(n_estimators=500, random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "y = train_df.is_duplicate.values\n",
    "pipe.fit(train_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:41:42.440603Z",
     "start_time": "2018-11-26T15:41:42.390019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mvp (tf-idf, nmf(5), xgboost)</th>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.670638</td>\n",
       "      <td>0.39413</td>\n",
       "      <td>0.496481</td>\n",
       "      <td>0.74804</td>\n",
       "      <td>0.563257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy  precision   recall        f1  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)  0.704833   0.670638  0.39413  0.496481   \n",
       "\n",
       "                                   auc  log_loss  \n",
       "mvp (tf-idf, nmf(5), xgboost)  0.74804  0.563257  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = utils.load('results')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:53:35.502774Z",
     "start_time": "2018-11-26T15:41:42.444323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mvp (tf-idf, nmf(5), xgboost)</th>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.670638</td>\n",
       "      <td>0.394130</td>\n",
       "      <td>0.496481</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>0.563257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvp (+ lemma)</th>\n",
       "      <td>0.699275</td>\n",
       "      <td>0.655821</td>\n",
       "      <td>0.390391</td>\n",
       "      <td>0.489436</td>\n",
       "      <td>0.742537</td>\n",
       "      <td>0.568832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy  precision    recall        f1  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)  0.704833   0.670638  0.394130  0.496481   \n",
       "mvp (+ lemma)                  0.699275   0.655821  0.390391  0.489436   \n",
       "\n",
       "                                    auc  log_loss  \n",
       "mvp (tf-idf, nmf(5), xgboost)  0.748040  0.563257  \n",
       "mvp (+ lemma)                  0.742537  0.568832  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this takes a long time, related to the lemmatization process\n",
    "results_df = results_df.append(utils.log_scores(pipe, train_df, y, 'mvp (+ lemma)'))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar results compared to the MVP. Need to analyze the pairs which are difficult to classify and determine the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If I tokenzie my training data, then do I need to do the same for test data when predicting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:03:52.006049Z",
     "start_time": "2018-11-26T17:03:49.274305Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.save(results_df, 'results')\n",
    "utils.save(pipe, 'mvp_lemma_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project5]",
   "language": "python",
   "name": "conda-env-project5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
