{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of attack\n",
    "\n",
    "1. Use spacy to better tokeninze the text.\n",
    "2. Build an custom text cleaner step in the pipeline process.\n",
    "3. Build document vector conversion step.\n",
    "4. Build the pairing of the questions, or somehow build in parallel.\n",
    "5. Run XGBoost to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:14.667101Z",
     "start_time": "2018-11-25T20:54:02.293663Z"
    }
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "from utils import save, load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# text manipulation\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:15.026904Z",
     "start_time": "2018-11-25T20:54:14.670602Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = load('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to clean bad text, and tokenize the Quora questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:15.034950Z",
     "start_time": "2018-11-25T20:54:15.029333Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(question):\n",
    "    ''' Pre-processeor to clean the Quora questions\n",
    "    '''\n",
    "    # found 1 example of no space after a question mark, which causes issues with the tokenzier\n",
    "    for p in punctuations:\n",
    "        question = question.replace(p, ' ')\n",
    "    \n",
    "    return question\n",
    "\n",
    "def spacy_tokenizer(question):\n",
    "    ''' Tokenizer that lemmatizes and removes stop words and punctuation\n",
    "    '''\n",
    "    tokens = nlp.tokenizer(question)\n",
    "#     tokens = [tok.lemma_.lower().strip() for tok in tokens if tok.lemma_ != '-PRON-']\n",
    "#     tokens = [tok for tok in tokens if tok not in punctuations and tok not in spacy_stopwords]     \n",
    "    \n",
    "    return [token.lemma_ for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:15.071897Z",
     "start_time": "2018-11-25T20:54:15.039063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can we know the number of people connected with the hotspot of Moto G4 Plus?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = train_df.loc[:,'question1'].sample(1).values[0]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:15.085027Z",
     "start_time": "2018-11-25T20:54:15.075995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'can',\n",
       " 'we',\n",
       " 'know',\n",
       " 'the',\n",
       " 'numb',\n",
       " 'of',\n",
       " 'people',\n",
       " 'connect',\n",
       " 'with',\n",
       " 'the',\n",
       " 'hotspot',\n",
       " 'of',\n",
       " 'Moto',\n",
       " 'G4',\n",
       " 'Plus',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenizer(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline will be the following,\n",
    "\n",
    "1. Transform pairs into documents\n",
    "2. TF-IDF of the transformation, with the `spacy_tokenizer`\n",
    "3. NMF with 50 components\n",
    "4. Transform the document back into pairs\n",
    "5. XGBoost classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:54:15.096963Z",
     "start_time": "2018-11-25T20:54:15.087617Z"
    }
   },
   "outputs": [],
   "source": [
    "def stack_questions(df):\n",
    "    ''' Takes the pair of questions, and stacks them as individual documents to be processed.\n",
    "    \n",
    "    df: DataFrame \n",
    "    The data frame must have the 3 cols (id, question1, question2).\n",
    "    \n",
    "    return: DataFrame\n",
    "    Returns a data frame of documents (questions)\n",
    "    '''\n",
    "    X = df.loc[:, ['id', 'question1']]\n",
    "    df = df.drop(columns='question1')\n",
    "    df = df.rename(columns={'question2':'question1'})\n",
    "    \n",
    "    X = X.append(df.loc[:, ['id', 'question1']], sort=False)\n",
    "    X = X.sort_values('id').reset_index()\n",
    "    \n",
    "    return np.array(X['question1'])\n",
    "\n",
    "def unstack_questions(X):\n",
    "    ''' Takes X (n_question*2, 1) and transforms it to a (n_questions, 2) numpy array. \n",
    "    '''\n",
    "    odd_idx = [i for i in range(len(X)) if i % 2 == 1]\n",
    "    even_idx = [i for i in range(len(X)) if i % 2 == 0]\n",
    "    \n",
    "    return np.hstack([X[odd_idx], X[even_idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a simple pipeline to confirm the questions can be transformed from pairs, to an array of documents, back to pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:56:04.372921Z",
     "start_time": "2018-11-25T20:54:15.100639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('stack', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function stack_questions at 0x1a8f8d4a60>,\n",
       "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "          pass_y='deprecated', validate=False)), ('tf', TfidfVectorizer(analyzer='word', binary=False,...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(stack_questions, validate=False)),\n",
    "        ('tf', TfidfVectorizer(stop_words=spacy_stopwords)),\n",
    "        ('nmf', NMF(n_components=5)),\n",
    "        ('unstack', FunctionTransformer(unstack_questions, validate=False)),\n",
    "        ('xgb', XGBClassifier(n_estimators=500, n_jobs=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "y = train_df.loc[:,'is_duplicate'].values\n",
    "pipeline.fit(train_df, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to see what the AUC is on the training data set, and also perform a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:56:04.385746Z",
     "start_time": "2018-11-25T20:56:04.376282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3692197711407835"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y == 1]) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:56:34.868441Z",
     "start_time": "2018-11-25T20:56:34.861415Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_scores(model, X, y, m_name, p_cut = 0.5):\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    score = (probs >= p_cut).astype(int)\n",
    "    \n",
    "    measures = np.array([\n",
    "        metrics.accuracy_score(y, score),\n",
    "        metrics.precision_score(y, score),\n",
    "        metrics.recall_score(y, score),\n",
    "        metrics.f1_score(y, score),\n",
    "        metrics.roc_auc_score(y, probs)\n",
    "    ])\n",
    "    \n",
    "    return pd.DataFrame(data = measures.reshape(1, 5), columns=['accuracy', 'precision', 'recall', 'f1', 'auc'], index=[m_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:56:48.827665Z",
     "start_time": "2018-11-25T20:56:36.341823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mvp (tf-idf, nmf(5), xgboost)</th>\n",
       "      <td>0.704685</td>\n",
       "      <td>0.672101</td>\n",
       "      <td>0.390847</td>\n",
       "      <td>0.494264</td>\n",
       "      <td>0.746805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy  precision    recall        f1  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)  0.704685   0.672101  0.390847  0.494264   \n",
       "\n",
       "                                    auc  \n",
       "mvp (tf-idf, nmf(5), xgboost)  0.746805  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = log_scores(pipeline, train_df, y, 'mvp (tf-idf, nmf(5), xgboost)')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:57:05.169919Z",
     "start_time": "2018-11-25T20:57:02.746780Z"
    }
   },
   "outputs": [],
   "source": [
    "save(pipeline, 'mvp_model')\n",
    "save(results_df, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "1. Add lemmatizer and fully incorporate a tokenizer with spacy.\n",
    "2. Analyze and determine if any further data cleaning is needed.\n",
    "  * Look at questions not ending in a ? mark.\n",
    "3. Build a pipeline using the GloVe vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project5]",
   "language": "python",
   "name": "conda-env-project5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
