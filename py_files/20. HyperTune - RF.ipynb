{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper - tuning - RF model\n",
    "\n",
    "The feature space, described below, and the RandomForrest classifier gives us the best validation AUC out of all other models. We will now use `BayesSearchCV` to hyper-tune the classifier on the feature space.\n",
    "\n",
    "Engineered two different types of features,\n",
    "\n",
    "1. n_gram similarity between each pair of questions\n",
    "2. min/max/avg distance between words in a single question. Currently using the following metrics,\n",
    "  * euclidean\n",
    "  * cosine\n",
    "  * city block or manhattan\n",
    "  \n",
    "**Pipeline**\n",
    "1. Stack questions\n",
    "2. Clean questions - now lower cases all words to better lemmatize proper nouns\n",
    "3. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distance\n",
    "4. Lemmatize questions\n",
    "5. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distances\n",
    "6. UNION together both sets of features\n",
    "7. Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# parameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')\n",
    "model_name = 'rf_hypertune'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text transformation and Feature Engineer pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text transformation pipes\n",
    "clean_text = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False))\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "lemma_text = Pipeline(\n",
    "    [\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# feature engineering pipes\n",
    "single_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('dist', FunctionTransformer(utils.add_min_max_avg_distance_features, validate=False)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pair_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('ngram_sim', FunctionTransformer(utils.calc_ngram_similarity, kw_args={'n_grams':[1, 2, 3]}, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleaned text only\n",
    "clean_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleanned and lemmatized text features\n",
    "lemma_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('lemma', lemma_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pre-process pipe\n",
    "feature_transformation = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_text_features', clean_text_features),\n",
    "                ('lemma_text_features', lemma_text_features)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 10min 40s, sys: 5min 58s, total: 1h 16min 39s\n",
      "Wall time: 25min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_transform = feature_transformation.transform(X_train) ## this takes a really long time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "# fixed params\n",
    "rf_params = {\n",
    "    'n_jobs': 4,\n",
    "    'random_state': 42,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# tuning parameters -- start with estimators as I know 500 gives a very good AUC\n",
    "rf_search_params = {\n",
    "    'n_estimators': Integer(500, 750)\n",
    "}\n",
    "\n",
    "bayes_params = {\n",
    "    'estimator': RandomForestClassifier(**rf_params),\n",
    "    'scoring': 'roc_auc',\n",
    "    'search_spaces': rf_search_params,\n",
    "    'n_iter': 10,\n",
    "    'cv': skf,\n",
    "    'n_jobs': 1,\n",
    "    'random_state': 42,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "search_cv = BayesSearchCV(**bayes_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(optim_results):\n",
    "    print(f'Best AUC: {search_cv_results.best_score_:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 603 out of 603 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 14.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:  5.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 709 out of 709 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 17.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 611 out of 611 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 14.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 703 out of 703 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 16.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 700 out of 700 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 684 out of 684 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 654 out of 654 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 12.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.772373\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 636 out of 636 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 636 out of 636 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 636 out of 636 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 636 out of 636 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 optim_result = self._step(\n\u001b[1;32m    653\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m                 )\n\u001b[1;32m    656\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             )\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             for train, test in cv_iter)\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_cv_results = search_cv.fit(X_train_transform, y_train, callback=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807296</td>\n",
       "      <td>0.804316</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.806759</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>1</td>\n",
       "      <td>131.529183</td>\n",
       "      <td>12.478978</td>\n",
       "      <td>2.250522</td>\n",
       "      <td>0.141808</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>552</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806255</td>\n",
       "      <td>0.803568</td>\n",
       "      <td>0.807976</td>\n",
       "      <td>0.805933</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>1</td>\n",
       "      <td>208.998184</td>\n",
       "      <td>2.855084</td>\n",
       "      <td>2.383416</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>652</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.806177</td>\n",
       "      <td>0.803546</td>\n",
       "      <td>0.807995</td>\n",
       "      <td>0.805906</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>1</td>\n",
       "      <td>193.943244</td>\n",
       "      <td>14.227560</td>\n",
       "      <td>2.188284</td>\n",
       "      <td>0.129094</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>582</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.806156</td>\n",
       "      <td>0.803565</td>\n",
       "      <td>0.807893</td>\n",
       "      <td>0.805871</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>1</td>\n",
       "      <td>258.290231</td>\n",
       "      <td>25.665571</td>\n",
       "      <td>2.720410</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>748</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800919</td>\n",
       "      <td>0.798106</td>\n",
       "      <td>0.802275</td>\n",
       "      <td>0.800434</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>1</td>\n",
       "      <td>177.414965</td>\n",
       "      <td>1.722789</td>\n",
       "      <td>3.251382</td>\n",
       "      <td>0.082671</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>966</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.800842</td>\n",
       "      <td>0.798036</td>\n",
       "      <td>0.802262</td>\n",
       "      <td>0.800380</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>1</td>\n",
       "      <td>171.988086</td>\n",
       "      <td>8.928521</td>\n",
       "      <td>2.989161</td>\n",
       "      <td>0.132966</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.799891</td>\n",
       "      <td>0.797249</td>\n",
       "      <td>0.801186</td>\n",
       "      <td>0.799442</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>1</td>\n",
       "      <td>292.883407</td>\n",
       "      <td>3.443255</td>\n",
       "      <td>3.663260</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>936</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.799905</td>\n",
       "      <td>0.797208</td>\n",
       "      <td>0.800985</td>\n",
       "      <td>0.799366</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>1</td>\n",
       "      <td>187.357691</td>\n",
       "      <td>6.478847</td>\n",
       "      <td>2.555201</td>\n",
       "      <td>0.426496</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>680</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.792160</td>\n",
       "      <td>0.789164</td>\n",
       "      <td>0.793501</td>\n",
       "      <td>0.791608</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>1</td>\n",
       "      <td>195.669708</td>\n",
       "      <td>7.524297</td>\n",
       "      <td>2.623955</td>\n",
       "      <td>0.174881</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>763</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.784138</td>\n",
       "      <td>0.780812</td>\n",
       "      <td>0.785160</td>\n",
       "      <td>0.783370</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>1</td>\n",
       "      <td>144.786910</td>\n",
       "      <td>11.266310</td>\n",
       "      <td>2.386551</td>\n",
       "      <td>0.373208</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>799</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'n_es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "2           0.807296           0.804316           0.808667         0.806759   \n",
       "1           0.806255           0.803568           0.807976         0.805933   \n",
       "5           0.806177           0.803546           0.807995         0.805906   \n",
       "7           0.806156           0.803565           0.807893         0.805871   \n",
       "0           0.800919           0.798106           0.802275         0.800434   \n",
       "9           0.800842           0.798036           0.802262         0.800380   \n",
       "8           0.799891           0.797249           0.801186         0.799442   \n",
       "6           0.799905           0.797208           0.800985         0.799366   \n",
       "4           0.792160           0.789164           0.793501         0.791608   \n",
       "3           0.784138           0.780812           0.785160         0.783370   \n",
       "\n",
       "   std_test_score  rank_test_score  mean_fit_time  std_fit_time  \\\n",
       "2        0.001816                1     131.529183     12.478978   \n",
       "1        0.001814                1     208.998184      2.855084   \n",
       "5        0.001827                1     193.943244     14.227560   \n",
       "7        0.001779                1     258.290231     25.665571   \n",
       "0        0.001736                1     177.414965      1.722789   \n",
       "9        0.001756                1     171.988086      8.928521   \n",
       "8        0.001638                1     292.883407      3.443255   \n",
       "6        0.001588                1     187.357691      6.478847   \n",
       "4        0.001813                1     195.669708      7.524297   \n",
       "3        0.001857                1     144.786910     11.266310   \n",
       "\n",
       "   mean_score_time  std_score_time param_criterion  param_max_depth  \\\n",
       "2         2.250522        0.141808            gini                6   \n",
       "1         2.383416        0.046274         entropy                6   \n",
       "5         2.188284        0.129094         entropy                6   \n",
       "7         2.720410        0.047840         entropy                6   \n",
       "0         3.251382        0.082671            gini                5   \n",
       "9         2.989161        0.132966            gini                5   \n",
       "8         3.663260        0.156456         entropy                5   \n",
       "6         2.555201        0.426496         entropy                5   \n",
       "4         2.623955        0.174881         entropy                4   \n",
       "3         2.386551        0.373208         entropy                3   \n",
       "\n",
       "   param_n_estimators                                             params  \n",
       "2                 552  {'criterion': 'gini', 'max_depth': 6, 'n_estim...  \n",
       "1                 652  {'criterion': 'entropy', 'max_depth': 6, 'n_es...  \n",
       "5                 582  {'criterion': 'entropy', 'max_depth': 6, 'n_es...  \n",
       "7                 748  {'criterion': 'entropy', 'max_depth': 6, 'n_es...  \n",
       "0                 966  {'criterion': 'gini', 'max_depth': 5, 'n_estim...  \n",
       "9                 871  {'criterion': 'gini', 'max_depth': 5, 'n_estim...  \n",
       "8                 936  {'criterion': 'entropy', 'max_depth': 5, 'n_es...  \n",
       "6                 680  {'criterion': 'entropy', 'max_depth': 5, 'n_es...  \n",
       "4                 763  {'criterion': 'entropy', 'max_depth': 4, 'n_es...  \n",
       "3                 799  {'criterion': 'entropy', 'max_depth': 3, 'n_es...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_cv_results.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(X_train_transform, y_train, stratify=y_train, random_state=42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=4, random_state=42, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_v_probs = rf.predict_proba(X_v)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8689592428199138"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_v, y_v_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
