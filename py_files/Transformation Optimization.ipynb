{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text transformation pipes\n",
    "clean_text = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False))\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "lemma_text = Pipeline(\n",
    "    [\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# feature engineering pipes\n",
    "single_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('dist', FunctionTransformer(utils.add_min_max_avg_distance_features, validate=False)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pair_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('ngram_sim', FunctionTransformer(utils.calc_ngram_similarity, kw_args={'n_grams':[1, 2, 3]}, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleaned text only\n",
    "clean_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleanned and lemmatized text features\n",
    "lemma_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('lemma', lemma_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pre-process pipe\n",
    "feature_transformation = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_text_features', clean_text_features),\n",
    "                ('lemma_text_features', lemma_text_features)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 80 ms, total: 1.8 s\n",
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_temp = utils.stack_questions(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.98 s, sys: 48 ms, total: 8.03 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_temp = utils.clean_questions(X_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 58s, sys: 1min 43s, total: 15min 42s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_temp_1 = utils.calc_ngram_similarity(X_temp, n_grams=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 22s, sys: 1min 1s, total: 23min 24s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_temp_2 = utils.add_min_max_avg_distance_features(X_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean_stack = utils.clean_questions(utils.stack_questions(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 54s, sys: 48.7 s, total: 7min 43s\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "master_doc = []\n",
    "for doc in utils.nlp.pipe(X_clean_stack, disable=['parser', 'ner'], batch_size=100000):\n",
    "    master_doc.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save(master_doc, 'master_doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_doc_2 = utils.load('master_doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what is the step by step guide to invest in share market in india"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_doc_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(foo)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1,819,194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1819194"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_temp)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 30 22:21:27 2018    restats\n",
      "\n",
      "         171431340 function calls (171410702 primitive calls) in 754.282 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 197 to 30 due to restriction <30>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000  754.282  754.282 {built-in method builtins.exec}\n",
      "        1    0.568    0.568  754.282  754.282 <string>:1(<module>)\n",
      "        1    8.136    8.136  753.714  753.714 /home/ubuntu/question_intent_classification/py_files/utils.py:321(add_min_max_avg_distance_features)\n",
      "  1819194   14.654    0.000  300.451    0.000 /home/ubuntu/question_intent_classification/py_files/utils.py:302(calc_min_max_avg_distance)\n",
      "   606399    0.679    0.000  278.963    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/spacy/language.py:521(pipe)\n",
      "      608    2.222    0.004  278.283    0.458 pipeline.pyx:430(pipe)\n",
      "      607    2.220    0.004  219.754    0.362 pipeline.pyx:437(predict)\n",
      "11533/1214    0.089    0.000  217.534    0.179 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/neural/_classes/model.py:155(__call__)\n",
      " 3642/607    1.055    0.000  210.623    0.347 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/api.py:53(predict)\n",
      "     1214    0.039    0.000  200.950    0.166 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/api.py:291(predict)\n",
      "  1818774   41.061    0.000  182.957    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scipy/spatial/distance.py:1609(pdist)\n",
      "     2428    2.272    0.001  165.929    0.068 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/neural/_classes/resnet.py:14(__call__)\n",
      "   606398   72.169    0.000  164.934    0.000 /home/ubuntu/question_intent_classification/py_files/utils.py:335(<listcomp>)\n",
      "     2428    8.056    0.003  131.570    0.054 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/neural/_classes/layernorm.py:43(predict)\n",
      "     2428   12.202    0.005   95.020    0.039 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/neural/_classes/maxout.py:58(predict)\n",
      " 12210850   90.018    0.000   90.018    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     4249   70.468    0.017   70.468    0.017 ops.pyx:333(batch_dot)\n",
      "  6722964   10.108    0.000   64.832    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "  1818774    6.525    0.000   55.519    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2817(mean)\n",
      "  6723571    8.020    0.000   55.103    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/_methods.py:34(_sum)\n",
      "  1821809   19.888    0.000   52.548    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/_methods.py:58(_mean)\n",
      "  8510352   52.458    0.000   52.458    0.000 {built-in method numpy.core.multiarray.array}\n",
      "   606399    0.973    0.000   42.681    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/spacy/language.py:551(<genexpr>)\n",
      "  1818774    9.345    0.000   42.100    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scipy/_lib/_util.py:192(_asarray_validated)\n",
      "   606398    0.884    0.000   41.708    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/spacy/language.py:371(make_doc)\n",
      "   606398    6.902    0.000   40.824    0.000 tokenizer.pyx:71(__call__)\n",
      "     1214    0.009    0.000   39.806    0.033 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/thinc/neural/_classes/model.py:124(predict)\n",
      "  4850344    5.665    0.000   39.790    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py:433(asarray)\n",
      "  3659400   13.030    0.000   39.077    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:64(_wrapreduction)\n",
      "  1818774   10.340    0.000   32.104    0.000 /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/scipy/spatial/distance.py:282(_validate_pdist_input)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f8a6b4fe8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "# import my_slow_module\n",
    "cProfile.run('utils.add_min_max_avg_distance_features(X_temp)', 'restats')\n",
    "p = pstats.Stats('restats')\n",
    "p.sort_stats('cumulative').print_stats(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, stratify=y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
