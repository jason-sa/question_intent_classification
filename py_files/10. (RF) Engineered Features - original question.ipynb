{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced featrue engineer model\n",
    "\n",
    "This model will add engineered features for the original question, in addition to the lemmatized question.\n",
    "\n",
    "Engineered two different types of features,\n",
    "\n",
    "1. n_gram similarity between each pair of questions\n",
    "2. min/max/avg distance between words in a single question. Currently using the following metrics,\n",
    "  * euclidean\n",
    "  * cosine\n",
    "  * city block or manhattan\n",
    "  \n",
    "**Pipeline**\n",
    "1. Stack questions\n",
    "2. Clean questions - now lower cases all words to better lemmatize proper nouns\n",
    "3. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distance\n",
    "4. Lemmatize questions\n",
    "5. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distances\n",
    "6. UNION together both sets of features\n",
    "7. Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:04.646711Z",
     "start_time": "2018-11-28T04:56:47.834474Z"
    }
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.108061Z",
     "start_time": "2018-11-28T04:57:04.649533Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.128186Z",
     "start_time": "2018-11-28T04:57:05.110672Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature engineering pipes\n",
    "single_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('dist', FunctionTransformer(utils.add_min_max_avg_distance_features, validate=False)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pair_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('ngram_sim', FunctionTransformer(utils.calc_ngram_similarity, kw_args={'n_grams':[1, 2, 3]}, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# clean text pipe\n",
    "clean_text_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# lemma pipe\n",
    "lemma_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False)),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pre-process pipe\n",
    "pre_process_pipe = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_features', clean_text_pipe),\n",
    "                ('lemma_pipe', lemma_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:09.161680Z",
     "start_time": "2018-11-28T04:57:05.134427Z"
    }
   },
   "outputs": [],
   "source": [
    "X_transform = pre_process_pipe.transform(X_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "cv = cross_validate(rf, \n",
    "               X_transform, \n",
    "               y_train, \n",
    "               cv=skf, \n",
    "               n_jobs=-1, \n",
    "               scoring=('accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>std_f1</th>\n",
       "      <th>avg_auc</th>\n",
       "      <th>std_auc</th>\n",
       "      <th>avg_log_loss</th>\n",
       "      <th>std_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mvp (tf-idf, nmf(5), xgboost)</th>\n",
       "      <td>0.700345</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.661571</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.385736</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.487325</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.740593</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.568958</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mvp (+ lemma)</th>\n",
       "      <td>0.696787</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.649977</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.387424</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.485464</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.738037</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.572483</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_model</th>\n",
       "      <td>0.710200</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.658748</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.446336</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.532120</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.746769</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.565250</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_sim_tfidf_model</th>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.659662</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.545419</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.597124</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.799173</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.513172</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_eng_model</th>\n",
       "      <td>0.743614</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.664102</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.618400</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.640434</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.489465</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_eng_model_lemma_fix</th>\n",
       "      <td>0.744356</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.664513</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.621357</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.822197</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.488131</td>\n",
       "      <td>0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_eng_model_lemma_clean</th>\n",
       "      <td>0.763927</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.676166</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.692113</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.684044</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.846923</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.456929</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_feat_eng_model_lemma_clean</th>\n",
       "      <td>0.783667</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.708853</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.702725</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.705774</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.868202</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.436197</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               avg_accuracy  std_accuracy  avg_precision  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)      0.700345      0.000466       0.661571   \n",
       "mvp (+ lemma)                      0.696787      0.001055       0.649977   \n",
       "cos_sim_model                      0.710200      0.000830       0.658748   \n",
       "cos_sim_tfidf_model                0.728261      0.001248       0.659662   \n",
       "feat_eng_model                     0.743614      0.002021       0.664102   \n",
       "feat_eng_model_lemma_fix           0.744356      0.002107       0.664513   \n",
       "feat_eng_model_lemma_clean         0.763927      0.002404       0.676166   \n",
       "rf_feat_eng_model_lemma_clean      0.783667      0.002260       0.708853   \n",
       "\n",
       "                               std_precision  avg_recall  std_recall  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)       0.000461    0.385736    0.002493   \n",
       "mvp (+ lemma)                       0.003057    0.387424    0.003230   \n",
       "cos_sim_model                       0.002578    0.446336    0.002215   \n",
       "cos_sim_tfidf_model                 0.002240    0.545419    0.001370   \n",
       "feat_eng_model                      0.003502    0.618400    0.001553   \n",
       "feat_eng_model_lemma_fix            0.004333    0.621357    0.000901   \n",
       "feat_eng_model_lemma_clean          0.003904    0.692113    0.001128   \n",
       "rf_feat_eng_model_lemma_clean       0.003681    0.702725    0.001666   \n",
       "\n",
       "                                 avg_f1    std_f1   avg_auc   std_auc  \\\n",
       "mvp (tf-idf, nmf(5), xgboost)  0.487325  0.001983  0.740593  0.001647   \n",
       "mvp (+ lemma)                  0.485464  0.002485  0.738037  0.001362   \n",
       "cos_sim_model                  0.532120  0.001306  0.746769  0.001279   \n",
       "cos_sim_tfidf_model            0.597124  0.001666  0.799173  0.001407   \n",
       "feat_eng_model                 0.640434  0.002281  0.821070  0.001428   \n",
       "feat_eng_model_lemma_fix       0.642201  0.001609  0.822197  0.001710   \n",
       "feat_eng_model_lemma_clean     0.684044  0.002549  0.846923  0.001643   \n",
       "rf_feat_eng_model_lemma_clean  0.705774  0.002658  0.868202  0.001148   \n",
       "\n",
       "                               avg_log_loss  std_log_loss  \n",
       "mvp (tf-idf, nmf(5), xgboost)      0.568958      0.001288  \n",
       "mvp (+ lemma)                      0.572483      0.000815  \n",
       "cos_sim_model                      0.565250      0.000963  \n",
       "cos_sim_tfidf_model                0.513172      0.001191  \n",
       "feat_eng_model                     0.489465      0.001141  \n",
       "feat_eng_model_lemma_fix           0.488131      0.001342  \n",
       "feat_eng_model_lemma_clean         0.456929      0.001410  \n",
       "rf_feat_eng_model_lemma_clean      0.436197      0.000640  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = utils.load('results')\n",
    "\n",
    "results_df = results_df.drop(index='rf_feat_eng_model_lemma_clean', errors='ignore')\n",
    "results_df = results_df.append(utils.log_scores(cv, 'rf_feat_eng_model_lemma_clean'))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save(results_df, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Wow! The feature engineering shows a significant jump in AUC from 0.8 to 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>prob</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gt   prob   diff\n",
       "0   0  0.150 -0.150\n",
       "1   0  0.180 -0.180\n",
       "2   0  0.086 -0.086\n",
       "3   0  0.000  0.000\n",
       "4   0  0.042 -0.042"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_transform, y_train)\n",
    "y_probs = rf.predict_proba(X_transform)[:, 1]\n",
    "class_errors_df = utils.ground_truth_analysis(y_train, y_probs)\n",
    "class_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False)),\n",
    "    ]\n",
    ")\n",
    "X_train_lemma = lemma_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top false negative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob: 0.022035150817837166\n",
      "\n",
      "Is unifunds.com legit?\n",
      "Is unifunds legit?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "unifund legit\n",
      "unifundscom legit\n",
      "\n",
      "Feature Space------\n",
      "[ 0.66666667  0.33333333  0.33333333  6.57793499  6.57793499  6.57793499\n",
      "  0.732846    0.732846    0.732846   88.33192412 88.33192412 88.33192412\n",
      "  6.57793499  6.57793499  6.57793499  0.732846    0.732846    0.732846\n",
      " 88.33192412 88.33192412 88.33192412  0.5         0.5         0.5\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.06587658468825115\n",
      "\n",
      "What is the remainder when 2^100 is divided by 101?\n",
      "What is the remainder when [math]2^{100}[/math] is divided by 101?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "remainder  divide\n",
      "remainder  divide\n",
      "\n",
      "Feature Space------\n",
      "[  1.           1.           1.           0.           7.61300637\n",
      "   5.48716164   0.           0.83449638   0.57976533   0.\n",
      " 105.72734378  74.80031913   0.           7.61300637   5.48716164\n",
      "   0.           0.83449638   0.57976533   0.         105.72734378\n",
      "  74.80031913   1.           1.           1.           6.180452\n",
      "   6.180452     6.180452     0.59770131   0.59770131   0.59770131\n",
      "  83.15616088  83.15616088  83.15616088   6.180452     6.180452\n",
      "   6.180452     0.59770131   0.59770131   0.59770131  83.15616088\n",
      "  83.15616088  83.15616088]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.08818307295783752\n",
      "\n",
      "I came to know after 13 years that I am adopted. What should I do?\n",
      "I came to know after 14 years that I am adopted. What should I do?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "come know  year adopt\n",
      "come know  year adopt\n",
      "\n",
      "Feature Space------\n",
      "[  1.           1.           1.           0.           8.42284733\n",
      "   5.67781296   0.           0.86054746   0.52033754   0.\n",
      " 112.61571255  76.84327644   0.           8.42284733   5.67781296\n",
      "   0.           0.86054746   0.52033754   0.         112.61571255\n",
      "  76.84327644   1.           1.           1.           4.10876014\n",
      "   7.34226788   6.01395107   0.31585093   0.76988591   0.58875571\n",
      "  55.9309944  100.95382794  81.94443333   4.10876014   7.34226788\n",
      "   6.01395107   0.31585093   0.76988591   0.58875571  55.9309944\n",
      " 100.95382794  81.94443333]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.16126124431124456\n",
      "\n",
      "What is the value of |1/0|?\n",
      "What is the value of 1/0?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "value\n",
      "value\n",
      "\n",
      "Feature Space------\n",
      "[ 1.          1.          1.          3.67209771  6.39188453  5.27503753\n",
      "  0.28606134  0.61919654  0.49754824 49.32912163 89.91105918 71.80362861\n",
      "  3.67209771  6.39188453  5.27503753  0.28606134  0.61919654  0.49754824\n",
      " 49.32912163 89.91105918 71.80362861  1.          1.          1.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.20181213786213814\n",
      "\n",
      "What business can I start with $500?\n",
      "What business can I start with $500-$600?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "business start\n",
      "business start\n",
      "\n",
      "Feature Space------\n",
      "[  1.           1.           1.           4.46446583   8.08658859\n",
      "   5.94760273   0.37809369   0.79417771   0.56278212  60.39175109\n",
      " 104.4274586   80.28625336   4.46446583   8.08658859   5.94760273\n",
      "   0.37809369   0.79417771   0.56278212  60.39175109 104.4274586\n",
      "  80.28625336   1.           1.           1.           6.43471449\n",
      "   6.43471449   6.43471449   0.57851419   0.57851419   0.57851419\n",
      "  86.93568682  86.93568682  86.93568682   6.43471449   6.43471449\n",
      "   6.43471449   0.57851419   0.57851419   0.57851419  86.93568682\n",
      "  86.93568682  86.93568682]\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_idx = class_errors_df.sort_values('diff', ascending = False).head().index\n",
    "for idx in fn_idx:\n",
    "    print('Prob:', y_probs[idx])\n",
    "    print()\n",
    "    print(X_train.iloc[idx].question1)\n",
    "    print(X_train.iloc[idx].question2)\n",
    "    print()\n",
    "    print('Lemma--------')\n",
    "    print()\n",
    "    print(X_train_lemma[idx*2])\n",
    "    print(X_train_lemma[idx*2+1])\n",
    "    print()\n",
    "    print('Feature Space------')\n",
    "    print(X_transform[idx])\n",
    "    print('-------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top false positive errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob: 0.859919422244422\n",
      "\n",
      "Can I make 30,000 a month betting on horses?\n",
      "Can I make 80,000 a month betting on horses?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      " month bet horse\n",
      " month bet horse\n",
      "\n",
      "Feature Space------\n",
      "[  1.           1.           1.           3.54843587   8.64389945\n",
      "   6.99204975   0.24125347   0.86209143   0.6860896   48.7158108\n",
      " 119.75634825  95.64765528   3.54843587   8.64389945   6.99204975\n",
      "   0.24125347   0.86209143   0.6860896   48.7158108  119.75634825\n",
      "  95.64765528   1.           1.           1.           6.92833324\n",
      "   8.06033018   7.32694928   0.60332816   0.81230419   0.70401332\n",
      "  95.01284819 112.79109566 101.19969094   6.92833324   8.06033018\n",
      "   7.32694928   0.60332816   0.81230419   0.70401332  95.01284819\n",
      " 112.79109566 101.19969094]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.8402367798867798\n",
      "\n",
      "What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Taiyuan?\n",
      "What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Eslands River?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "significance battle somme battle compare contrast battle esland river\n",
      "significance battle somme battle compare contrast battle taiyuan\n",
      "\n",
      "Feature Space------\n",
      "[  0.90322581   0.87804878   0.8372093    0.           8.94758213\n",
      "   5.63428436   0.           1.14395334   0.58597778   0.\n",
      " 119.74790659  76.10832393   0.           9.47086476   5.85348526\n",
      "   0.           1.14395334   0.60099757   0.         123.61142434\n",
      "  79.3040757    0.76923077   0.70588235   0.58823529   0.\n",
      "   8.94758213   6.58424623   0.           1.07835326   0.69907214\n",
      "   0.         119.74790659  88.10770493   0.           9.47086476\n",
      "   7.08213208   0.           1.07835326   0.72237867   0.\n",
      " 123.61142434  95.47296559]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.6774357142857147\n",
      "\n",
      "What is the best way to invest $1,000?\n",
      "How should I invest $3,000?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "invest\n",
      "good way invest\n",
      "\n",
      "Feature Space------\n",
      "[  0.18181818   0.18181818   0.18181818   3.32768196   6.91181574\n",
      "   5.05989927   0.22358162   0.77860875   0.48962364  44.39012259\n",
      "  96.74042761  69.17308505   4.4516778    7.68992106   6.03018017\n",
      "   0.36869252   0.74090815   0.54074633  59.87225566 102.96853832\n",
      "  81.7893619    0.5          0.5          0.5          3.77246627\n",
      "   6.56454039   5.47342111   0.27768882   0.64414244   0.50415504\n",
      "  52.96125268  88.30038751  74.88121715   0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.        ]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.6641166666666668\n",
      "\n",
      "What was the significance of the battle of Somme, and how did this battle compare and contrast to the Battle of Tubruk?\n",
      "What is the significance of the Battle of the Somme?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "significance battle somme battle compare contrast battle tubruk\n",
      "significance battle somme\n",
      "\n",
      "Feature Space------\n",
      "[  0.54545455   0.34482759   0.25806452   0.           8.42572447\n",
      "   5.34892541   0.           1.11076426   0.56015726   0.\n",
      " 108.96536596  71.61586506   0.           8.94758213   5.63428436\n",
      "   0.           1.14395334   0.58597778   0.         119.74790659\n",
      "  76.10832393   0.66666667   0.36363636   0.18181818   7.36709745\n",
      "   8.37483324   8.00541642   0.74473765   0.95203243   0.85245005\n",
      "  98.62492535 108.96536596 103.27576907   0.           8.94758213\n",
      "   6.58424623   0.           1.07835326   0.69907214   0.\n",
      " 119.74790659  88.10770493]\n",
      "-------------------------------------------\n",
      "\n",
      "Prob: 0.6129852203352205\n",
      "\n",
      "How should I prepare for aipmt 2017?\n",
      "How do I prepare for AIPMT?\n",
      "\n",
      "Lemma--------\n",
      "\n",
      "prepare aipmt\n",
      "prepare aipmt\n",
      "\n",
      "Feature Space------\n",
      "[  0.83333333   0.66666667   0.66666667   4.4516778    7.75465252\n",
      "   5.9052204    0.36869252   0.76868073   0.55995017  59.87225566\n",
      " 103.9713506   80.15020918   4.30849117   7.75465252   6.02775601\n",
      "   0.31031856   0.76868073   0.56703872  58.54252309 103.9713506\n",
      "  82.12957679   1.           1.           1.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.        ]\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn_idx = class_errors_df.sort_values('diff').head().index\n",
    "for idx in fn_idx:\n",
    "    print('Prob:', y_probs[idx])\n",
    "    print()\n",
    "    print(X_train.iloc[idx].question1)\n",
    "    print(X_train.iloc[idx].question2)\n",
    "    print()\n",
    "    print('Lemma--------')\n",
    "    print()\n",
    "    print(X_train_lemma[idx*2])\n",
    "    print(X_train_lemma[idx*2+1])\n",
    "    print()\n",
    "    print('Feature Space------')\n",
    "    print(X_transform[idx])\n",
    "    print('-------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. The set of false negative and false postive errors appears to be different compared to XGBoost model. \n",
    "  * Run an ensemble model with RandomForrest and XGBoost to smooth out the bias.\n",
    "2. Short questions with numbers and stop words seem to be a common theme for the false positive errors. \n",
    "  * Generate features including stop words and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
