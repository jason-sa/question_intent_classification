{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper - tuning - RF model\n",
    "\n",
    "The feature space, described below, and the RandomForrest classifier gives us the best validation AUC out of all other models. We will now use `BayesSearchCV` to hyper-tune the classifier on the feature space.\n",
    "\n",
    "Engineered two different types of features,\n",
    "\n",
    "1. n_gram similarity between each pair of questions\n",
    "2. min/max/avg distance between words in a single question. Currently using the following metrics,\n",
    "  * euclidean\n",
    "  * cosine\n",
    "  * city block or manhattan\n",
    "  \n",
    "**Pipeline**\n",
    "1. Stack questions\n",
    "2. Clean questions - now lower cases all words to better lemmatize proper nouns\n",
    "3. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distance\n",
    "4. Lemmatize questions\n",
    "5. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distances\n",
    "6. UNION together both sets of features\n",
    "7. Random Forrest\n",
    "\n",
    "**Changes**\n",
    "* Fix the n_estimators to 500 and search other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# parameter search\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')\n",
    "model_name = 'rf_hypertune'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text transformation and Feature Engineer pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text transformation pipes\n",
    "clean_text = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False))\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "lemma_text = Pipeline(\n",
    "    [\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# feature engineering pipes\n",
    "single_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('dist', FunctionTransformer(utils.add_min_max_avg_distance_features, validate=False)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pair_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('ngram_sim', FunctionTransformer(utils.calc_ngram_similarity, kw_args={'n_grams':[1, 2, 3]}, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleaned text only\n",
    "clean_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# build features on the cleanned and lemmatized text features\n",
    "lemma_text_features = Pipeline(\n",
    "    [\n",
    "        ('clean', clean_text),\n",
    "        ('lemma', lemma_text),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pre-process pipe\n",
    "feature_transformation = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_text_features', clean_text_features),\n",
    "                ('lemma_text_features', lemma_text_features)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 64 ms, total: 80 ms\n",
      "Wall time: 79 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    X_train_transform = utils.load('X_train_transform')\n",
    "except:\n",
    "    X_train_transform = feature_transformation.transform(X_train) ## this takes a really long time\n",
    "    utils.save(X_train_transform, 'X_train_transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "# fixed params\n",
    "rf_params = {\n",
    "#     'n_estimators': 500,\n",
    "    'n_jobs': 4,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# tuning parameters -- start with estimators as I know 500 gives a very good AUC\n",
    "rf_search_params = {\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'min_samples_leaf': Integer(1, 4),\n",
    "    'n_estimators': Integer(584,700)\n",
    "}\n",
    "\n",
    "bayes_params = {\n",
    "    'estimator': RandomForestClassifier(**rf_params),\n",
    "    'scoring': 'roc_auc',\n",
    "    'search_spaces': rf_search_params,\n",
    "    'n_iter': 3,\n",
    "    'cv': skf,\n",
    "    'n_jobs': 1,\n",
    "    'random_state': 42,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "search_cv = BayesSearchCV(**bayes_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress(optim_results):\n",
    "    print(f'Best AUC: {search_cv.best_score_:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 15.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.865357\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.865357\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.865357\n",
      "CPU times: user 37min 49s, sys: 4min 19s, total: 42min 8s\n",
      "Wall time: 49min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_cv_results = search_cv.fit(X_train_transform, y_train, callback=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.863866</td>\n",
       "      <td>0.866661</td>\n",
       "      <td>0.865357</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>1</td>\n",
       "      <td>299.439168</td>\n",
       "      <td>0.613496</td>\n",
       "      <td>6.363648</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>692</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.864886</td>\n",
       "      <td>0.863294</td>\n",
       "      <td>0.866188</td>\n",
       "      <td>0.864789</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>1</td>\n",
       "      <td>256.508619</td>\n",
       "      <td>0.726135</td>\n",
       "      <td>5.458807</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>596</td>\n",
       "      <td>{'min_samples_leaf': 2, 'min_samples_split': 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.863357</td>\n",
       "      <td>0.861639</td>\n",
       "      <td>0.864745</td>\n",
       "      <td>0.863247</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>1</td>\n",
       "      <td>263.271633</td>\n",
       "      <td>5.002940</td>\n",
       "      <td>5.527277</td>\n",
       "      <td>0.050183</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>619</td>\n",
       "      <td>{'min_samples_leaf': 4, 'min_samples_split': 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.865546           0.863866           0.866661         0.865357   \n",
       "2           0.864886           0.863294           0.866188         0.864789   \n",
       "1           0.863357           0.861639           0.864745         0.863247   \n",
       "\n",
       "   std_test_score  rank_test_score  mean_fit_time  std_fit_time  \\\n",
       "0        0.001149                1     299.439168      0.613496   \n",
       "2        0.001184                1     256.508619      0.726135   \n",
       "1        0.001271                1     263.271633      5.002940   \n",
       "\n",
       "   mean_score_time  std_score_time  param_min_samples_leaf  \\\n",
       "0         6.363648        0.003194                       2   \n",
       "2         5.458807        0.001653                       2   \n",
       "1         5.527277        0.050183                       4   \n",
       "\n",
       "   param_min_samples_split  param_n_estimators  \\\n",
       "0                        8                 692   \n",
       "2                        9                 596   \n",
       "1                        9                 619   \n",
       "\n",
       "                                              params  \n",
       "0  {'min_samples_leaf': 2, 'min_samples_split': 8...  \n",
       "2  {'min_samples_leaf': 2, 'min_samples_split': 9...  \n",
       "1  {'min_samples_leaf': 4, 'min_samples_split': 9...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search_cv_results.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 584,\n",
       " 'n_jobs': 4,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cv_results.best_estimator_.get_params() #AUC .868429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_v, y_t, y_v = train_test_split(X_train_transform, y_train, stratify=y_train, random_state=42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=4, random_state=42, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_v_probs = rf.predict_proba(X_v)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8689592428199138"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_v, y_v_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
