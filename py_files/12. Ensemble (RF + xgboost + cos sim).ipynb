{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced featrue engineer model\n",
    "\n",
    "This model will add engineered features for the original question, in addition to the lemmatized question.\n",
    "\n",
    "Engineered two different types of features,\n",
    "\n",
    "1. n_gram similarity between each pair of questions\n",
    "2. min/max/avg distance between words in a single question. Currently using the following metrics,\n",
    "  * euclidean\n",
    "  * cosine\n",
    "  * city block or manhattan\n",
    "  \n",
    "**Pipeline**\n",
    "1. Stack questions\n",
    "2. Clean questions - now lower cases all words to better lemmatize proper nouns\n",
    "3. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distance\n",
    "4. Lemmatize questions\n",
    "5. UNION\n",
    "    1. n_gram similarity\n",
    "    2. min/max/avg distances\n",
    "6. UNION together both sets of features\n",
    "7. Avearge Ensemble\n",
    "    1. Random Forrest\n",
    "    2. XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:04.646711Z",
     "start_time": "2018-11-28T04:56:47.834474Z"
    }
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.108061Z",
     "start_time": "2018-11-28T04:57:04.649533Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = utils.load('X_train')\n",
    "y_train = utils.load('y_train')\n",
    "MEM_PATH = '../data/transform_memory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cos similarity of TF-IDF vector plus NMF topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_pipe = Pipeline(\n",
    "    [\n",
    "        ('nmf', NMF(n_components=5)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cos_pipe = Pipeline(\n",
    "    [\n",
    "        ('cos', FunctionTransformer(utils.calc_cos_sim_stack, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "nmf_cos_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False)),\n",
    "        ('tf', TfidfVectorizer()),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('nmf_pipe', nmf_pipe),\n",
    "                ('cos_pipe', cos_pipe)\n",
    "            ]\n",
    "        )),\n",
    "        ('xgb', XGBClassifier(n_estimators=500, n_jobs=-1, random_state=42))\n",
    "    ],\n",
    "    memory = MEM_PATH\n",
    ")\n",
    "# X_transform = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.128186Z",
     "start_time": "2018-11-28T04:57:05.110672Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature engineering pipes\n",
    "single_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('dist', FunctionTransformer(utils.add_min_max_avg_distance_features, validate=False)),\n",
    "        ('unstack', FunctionTransformer(utils.unstack_questions, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pair_question_pipe = Pipeline(\n",
    "    [\n",
    "        ('ngram_sim', FunctionTransformer(utils.calc_ngram_similarity, kw_args={'n_grams':[1, 2, 3]}, validate=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# clean text pipe\n",
    "clean_text_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# lemma pipe\n",
    "lemma_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False)),\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('pair', pair_question_pipe),\n",
    "                ('single', single_question_pipe)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.128186Z",
     "start_time": "2018-11-28T04:57:05.110672Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "XGB_pipe = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_features', clean_text_pipe),\n",
    "                ('lemma_pipe', lemma_pipe)\n",
    "            ]\n",
    "        )),\n",
    "        ('xgb', XGBClassifier(n_estimators=500, n_jobs=-1, random_state=42))\n",
    "    ],\n",
    "    memory = MEM_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pipe = Pipeline(\n",
    "    [\n",
    "        ('feats', FeatureUnion(\n",
    "            [\n",
    "                ('clean_features', clean_text_pipe),\n",
    "                ('lemma_pipe', lemma_pipe)\n",
    "            ]\n",
    "        )),\n",
    "        ('rf', RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42))\n",
    "    ],\n",
    "    memory = MEM_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:05.128186Z",
     "start_time": "2018-11-28T04:57:05.110672Z"
    }
   },
   "outputs": [],
   "source": [
    "# weighting based on individual AUC\n",
    "## cos_sim = 0.799173\n",
    "## xgboost = 0.846923\n",
    "## rf = 0.868202\n",
    "\n",
    "total = 0.799173 + 0.846923 + 0.868202\n",
    "cos_sim_weight = 0.799173 / total\n",
    "xgb_weight = 0.846923 / total\n",
    "rf_weight = 0.868202 / total\n",
    "\n",
    "weights = [cos_sim_weight, xgb_weight, rf_weight]\n",
    "estimators = [('cos_sim', nmf_cos_pipe), ('xgb', XGB_pipe), ('rf', RF_pipe)]\n",
    "vc = VotingClassifier(estimators, voting='soft', n_jobs=-1, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T04:57:09.161680Z",
     "start_time": "2018-11-28T04:57:05.134427Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-df273e3b71f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                scoring=('accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_transform = pre_process_pipe.transform(X_train)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "cv = cross_validate(vc, \n",
    "               X_train, \n",
    "               y_train, \n",
    "               cv=skf, \n",
    "               n_jobs=-1, \n",
    "               scoring=('accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'neg_log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = utils.load('results')\n",
    "\n",
    "results_df = results_df.drop(index='ensemble_rf_xgb_cos_sim', errors='ignore')\n",
    "results_df = results_df.append(utils.log_scores(cv, 'ensemble_rf_xgb_cos_sim'))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save(results_df, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Wow! The feature engineering shows a significant jump in AUC from 0.8 to 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we...ate=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = VotingClassifier([('rf', rf), ('xgb', xgb)], voting='soft')\n",
    "vc.fit(X_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>prob</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.271811</td>\n",
       "      <td>-0.271811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.331749</td>\n",
       "      <td>-0.331749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.158016</td>\n",
       "      <td>-0.158016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>-0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034689</td>\n",
       "      <td>-0.034689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gt      prob      diff\n",
       "0   0  0.271811 -0.271811\n",
       "1   0  0.331749 -0.331749\n",
       "2   0  0.158016 -0.158016\n",
       "3   0  0.000237 -0.000237\n",
       "4   0  0.034689 -0.034689"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = vc.predict_proba(X_transform)[:, 1]\n",
    "class_errors_df = utils.ground_truth_analysis(y_train, y_probs)\n",
    "class_errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_pipe = Pipeline(\n",
    "    [\n",
    "        ('stack', FunctionTransformer(utils.stack_questions, validate=False)),\n",
    "        ('clean', FunctionTransformer(utils.clean_questions, validate=False)),\n",
    "        ('lemma', FunctionTransformer(utils.apply_lemma, validate=False)),\n",
    "    ]\n",
    ")\n",
    "X_train_lemma = lemma_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top false negative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_idx = class_errors_df.sort_values('diff', ascending = False).head().index\n",
    "for idx in fn_idx:\n",
    "    print('Prob:', y_probs[idx])\n",
    "    print()\n",
    "    print(X_train.iloc[idx].question1)\n",
    "    print(X_train.iloc[idx].question2)\n",
    "    print()\n",
    "    print('Lemma--------')\n",
    "    print()\n",
    "    print(X_train_lemma[idx*2])\n",
    "    print(X_train_lemma[idx*2+1])\n",
    "    print()\n",
    "    print('Feature Space------')\n",
    "    print(X_transform[idx])\n",
    "    print('-------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top false positive errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_idx = class_errors_df.sort_values('diff').head().index\n",
    "for idx in fn_idx:\n",
    "    print('Prob:', y_probs[idx])\n",
    "    print()\n",
    "    print(X_train.iloc[idx].question1)\n",
    "    print(X_train.iloc[idx].question2)\n",
    "    print()\n",
    "    print('Lemma--------')\n",
    "    print()\n",
    "    print(X_train_lemma[idx*2])\n",
    "    print(X_train_lemma[idx*2+1])\n",
    "    print()\n",
    "    print('Feature Space------')\n",
    "    print(X_transform[idx])\n",
    "    print('-------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. The false negative errors appear to be related to numbers. \n",
    "  * Either stop removing numebers in the clean text proces, or create another set of features.\n",
    "2. The false positives seem very tricky. Found the Facebook InferSent model which embeds sentences to 4096 dimension.\n",
    "  * Could see if the distances between some of the false positive examples is different in this space.\n",
    "3. Could look at alignments of the two questions. (I think nltk)\n",
    "4. Add different word embeddings to get a different nuance, or even use the vector only data set from Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
